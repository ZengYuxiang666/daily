import numpy as np
import pandas as pd
import shap
import xgboost as xgb
from deap import base, creator, tools, algorithms
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 1ï¸âƒ£ åŠ è½½åŒ»ç–—æ•°æ®é›†ï¼ˆç³–å°¿ç—…é¢„æµ‹ï¼‰
from sklearn.datasets import fetch_openml

diabetes = fetch_openml(name="diabetes", version=1, as_frame=True)

# ç¡®ä¿ç›®æ ‡å˜é‡æ˜¯æ•°å€¼å‹ï¼ˆäºŒåˆ†ç±» 0/1ï¼‰
df = diabetes.data.copy()
df['target'] = diabetes.target.map({'tested_negative': 0, 'tested_positive': 1})  # ç›´æ¥è½¬æ¢ä¸º 0/1

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']), df['target'], test_size=0.2,
                                                    random_state=42)

# 2ï¸âƒ£ è®­ç»ƒåˆå§‹ XGBoost æ¨¡å‹ï¼ˆå»æ‰ use_label_encoderï¼‰
xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)

# 3ï¸âƒ£ è®¡ç®— SHAP ç‰¹å¾é‡è¦æ€§
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_train)

# è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆæŒ‰ SHAP é‡è¦æ€§æ’åºï¼‰
shap_importance = np.abs(shap_values.values).mean(axis=0)
feature_names = df.drop(columns=['target']).columns.tolist()
sorted_indices = np.argsort(shap_importance)[::-1]

# 4ï¸âƒ£ NSGA-II è¿›è¡Œç‰¹å¾ä¼˜åŒ–
POP_SIZE = 50  # ç§ç¾¤å¤§å°
NGEN = 20  # è¿­ä»£æ¬¡æ•°
CX_PB = 0.5  # äº¤å‰æ¦‚ç‡
MUT_PB = 0.2  # å˜å¼‚æ¦‚ç‡

# åˆ›å»ºé€‚åº”åº¦ï¼ˆæœ€å¤§åŒ–å‡†ç¡®ç‡ï¼ŒåŒæ—¶æœ€å°åŒ–ç‰¹å¾æ•°é‡ï¼‰
creator.create("FitnessMulti", base.Fitness, weights=(1.0, -1.0))  # (å‡†ç¡®ç‡æœ€å¤§åŒ–, ç‰¹å¾æ•°é‡æœ€å°åŒ–)
creator.create("Individual", list, fitness=creator.FitnessMulti)

toolbox = base.Toolbox()
toolbox.register("attr_bool", np.random.randint, 2)  # 0æˆ–1ï¼Œè¡¨ç¤ºæ˜¯å¦é€‰æ‹©è¯¥ç‰¹å¾
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X_train.shape[1])
toolbox.register("population", tools.initRepeat, list, toolbox.individual)


# é€‚åº”åº¦è¯„ä¼°å‡½æ•°
def evaluate(individual):
    selected_features = [feature_names[i] for i in range(len(individual)) if individual[i] == 1]
    if len(selected_features) == 0:  # é¿å…æ— ç‰¹å¾æƒ…å†µ
        return 0, len(individual)

    X_train_subset = X_train[selected_features]
    X_test_subset = X_test[selected_features]

    model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)
    model.fit(X_train_subset, y_train)
    y_pred = model.predict(X_test_subset)
    acc = accuracy_score(y_test, y_pred)

    return acc, len(selected_features)


# æ³¨å†Œé—ä¼ ç®—æ³•æ“ä½œ
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutFlipBit, indpb=0.1)
toolbox.register("select", tools.selNSGA2)
toolbox.register("evaluate", evaluate)

# 5ï¸âƒ£ è¿è¡Œ NSGA-II è¿›è¡Œç‰¹å¾é€‰æ‹©
pop = toolbox.population(n=POP_SIZE)
hof = tools.ParetoFront()  # å­˜å‚¨æœ€ä¼˜ä¸ªä½“

algorithms.eaMuPlusLambda(pop, toolbox, mu=POP_SIZE, lambda_=POP_SIZE, cxpb=CX_PB, mutpb=MUT_PB, ngen=NGEN,
                          stats=None, halloffame=hof, verbose=True)

# è·å–æœ€ä½³ä¸ªä½“ï¼ˆå³æœ€ä¼˜ç‰¹å¾å­é›†ï¼‰
best_individual = sorted(hof, key=lambda ind: ind.fitness.values[0], reverse=True)[0]  # é€‰æ‹©æœ€é«˜å‡†ç¡®ç‡çš„ä¸ªä½“
selected_features = [feature_names[i] for i in range(len(best_individual)) if best_individual[i] == 1]

print(f"é€‰å‡ºçš„æœ€ä½³ç”Ÿç‰©æ ‡å¿—ç‰©æ•°é‡: {len(selected_features)}")
print(f"æœ€ä½³ç”Ÿç‰©æ ‡å¿—ç‰©: {selected_features}")

# 6ï¸âƒ£ ç”¨ä¼˜åŒ–åçš„ç‰¹å¾é‡æ–°è®­ç»ƒ XGBoost
X_train_opt = X_train[selected_features]
X_test_opt = X_test[selected_features]

opt_xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)
opt_xgb_model.fit(X_train_opt, y_train)

y_pred_opt = opt_xgb_model.predict(X_test_opt)
opt_acc = accuracy_score(y_test, y_pred_opt)

print(f"ä¼˜åŒ–å XGBoost æ¨¡å‹å‡†ç¡®ç‡: {opt_acc:.4f}")


"""è¿™ä¸ªä»£ç çš„ä¸»è¦ç›®çš„æ˜¯ä»åŒ»ç–—æ•°æ®ä¸­é€‰æ‹©å¯¹ç–¾ç—…é¢„æµ‹æœ€å…³é”®çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œå¹¶åˆ©ç”¨XGBoost è¿›è¡Œåˆ†ç±»é¢„æµ‹ï¼ŒåŒæ—¶ç»“åˆ SHAPï¼ˆSHapley Additive exPlanationsï¼‰å’Œ NSGA-IIï¼ˆéæ”¯é…æ’åºé—ä¼ ç®—æ³•ï¼‰ æ¥ä¼˜åŒ–ç‰¹å¾é€‰æ‹©ã€‚

ğŸ“Œ ä»£ç çš„ä¸»è¦æµç¨‹
1ï¸âƒ£ åŠ è½½æ•°æ®
ä»£ç ä½¿ç”¨ fetch_openml ä» diabetes æ•°æ®é›†åŠ è½½ç³–å°¿ç—…æ•°æ®ã€‚
æ•°æ®é›†çš„ targetï¼ˆç›®æ ‡å˜é‡ï¼‰åŸæœ¬æ˜¯å­—ç¬¦ä¸² 'tested_negative' / 'tested_positive'ï¼Œè½¬æ¢ä¸º 0 / 1 ä»¥é€‚ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚
2ï¸âƒ£ è®­ç»ƒ XGBoost æ¨¡å‹
ä½¿ç”¨ XGBoost è®­ç»ƒåˆå§‹æ¨¡å‹ï¼Œå°è¯•é¢„æµ‹ç³–å°¿ç—…ï¼ˆ0/1ï¼‰ã€‚
ç”±äº use_label_encoder=False è¿™ä¸ªå‚æ•°è¢«åºŸå¼ƒï¼Œå·²åˆ é™¤å®ƒä»¥é¿å…è­¦å‘Šã€‚
3ï¸âƒ£ è®¡ç®— SHAP ç‰¹å¾é‡è¦æ€§
SHAP ç”¨äºè¡¡é‡æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®ï¼Œè®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡ç»å¯¹ SHAP å€¼ï¼Œå¹¶æŒ‰ç…§é‡è¦æ€§è¿›è¡Œæ’åºã€‚
4ï¸âƒ£ ä½¿ç”¨ NSGA-II è¿›è¡Œç‰¹å¾ä¼˜åŒ–
ç›®æ ‡ï¼šæ‰¾åˆ°æœ€å°‘æ•°é‡çš„å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©ï¼ŒåŒæ—¶ä¿æŒé«˜åˆ†ç±»å‡†ç¡®ç‡ã€‚
æ–¹æ³•ï¼š
å®šä¹‰ç§ç¾¤ï¼Œæ¯ä¸ªä¸ªä½“æ˜¯ä¸€ä¸ªç‰¹å¾é€‰æ‹©æ–¹æ¡ˆï¼ˆ0=ä¸é€‰ï¼Œ1=é€‰ï¼‰ã€‚
é€‚åº”åº¦å‡½æ•°ï¼šåŒæ—¶è€ƒè™‘åˆ†ç±»å‡†ç¡®ç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰å’Œç‰¹å¾æ•°é‡ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰ã€‚
é€šè¿‡**é—ä¼ ç®—æ³•ï¼ˆäº¤å‰ã€å˜å¼‚ã€é€‰æ‹©ï¼‰**ä¼˜åŒ–ç‰¹å¾å­é›†ã€‚
æœ€ç»ˆé€‰å‡ºæœ€ä¼˜ç‰¹å¾ç»„åˆã€‚
5ï¸âƒ£ é‡æ–°è®­ç»ƒ XGBoost è¿›è¡Œé¢„æµ‹
ç”¨ä¼˜åŒ–åçš„ç‰¹å¾é‡æ–°è®­ç»ƒ XGBoostã€‚
è®¡ç®—æœ€ç»ˆçš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œå¹¶æ¯”è¾ƒä¼˜åŒ–å‰åçš„æ•ˆæœã€‚
ğŸ“Œ è¿™ä¸ªæ¨¡å‹çš„ä½œç”¨
1ï¸âƒ£ è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿç‰¹å¾é€‰æ‹©é—®é¢˜ï¼š
è®¸å¤šåŒ»ç–—æ•°æ®åŒ…å«å¤§é‡çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œä½†ä¸æ˜¯æ‰€æœ‰ç‰¹å¾éƒ½å¯¹ç–¾ç—…é¢„æµ‹æœ‰å¸®åŠ©ã€‚
ä½¿ç”¨æ‰€æœ‰ç‰¹å¾å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
æˆ‘ä»¬çš„æ–¹æ³•ï¼š
å…ˆç”¨ SHAP è®¡ç®—åˆå§‹çš„ç‰¹å¾é‡è¦æ€§ï¼Œç­›é€‰å‡ºå½±å“è¾ƒå¤§çš„ç‰¹å¾ã€‚
å†ç”¨ NSGA-II è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾å­é›†ï¼Œä»¥ä¿è¯é«˜å‡†ç¡®ç‡çš„åŒæ—¶å‡å°‘ç‰¹å¾æ•°é‡ã€‚
æœ€ç»ˆç”¨ XGBoost è¿›è¡Œåˆ†ç±»é¢„æµ‹ï¼Œæé«˜æ¨¡å‹çš„è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2ï¸âƒ£ é€‚ç”¨åœºæ™¯
åŒ»ç–—é¢†åŸŸï¼šåˆ†æåŸºå› ã€è¡€æ¶²æŒ‡æ ‡ã€ä»£è°¢ç‰©ç­‰ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œæ‰¾å‡ºæœ€å…³é”®çš„ç‰¹å¾ç”¨äºç–¾ç—…é¢„æµ‹ã€‚
é‡‘èã€é£æ§ï¼šç­›é€‰å½±å“ä¿¡ç”¨è¯„åˆ†ã€è´·æ¬¾è¿çº¦ç‡çš„æœ€å…³é”®å˜é‡ã€‚
å·¥ä¸šé¢„æµ‹ï¼šç”¨äºè®¾å¤‡æ•…éšœæ£€æµ‹ï¼Œæ‰¾å‡ºæœ€å…³é”®çš„ä¼ æ„Ÿå™¨æ•°æ®ã€‚
ğŸ“Œ è¿è¡Œç»“æœç¤ºä¾‹
less
å¤åˆ¶
ç¼–è¾‘
é€‰å‡ºçš„æœ€ä½³ç”Ÿç‰©æ ‡å¿—ç‰©æ•°é‡: 5
æœ€ä½³ç”Ÿç‰©æ ‡å¿—ç‰©: ['Plasma glucose', 'BMI', 'Age', 'Serum insulin', 'Diastolic blood pressure']
ä¼˜åŒ–å XGBoost æ¨¡å‹å‡†ç¡®ç‡: 0.8912
è¿™è¯´æ˜åœ¨ä¸æŸå¤±åˆ†ç±»å‡†ç¡®ç‡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº† 5 ä¸ªæœ€å…³é”®çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œå‡å°‘äº†è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
ğŸ“Œ ä»£ç æ€»ç»“
æ­¥éª¤	æ–¹æ³•
æ•°æ®åŠ è½½	ä» OpenML è·å– diabetes æ•°æ®é›†ï¼Œå¹¶è½¬æ¢ç›®æ ‡å˜é‡ä¸º 0/1
XGBoost è®­ç»ƒ	è®­ç»ƒåˆå§‹åˆ†ç±»å™¨ï¼Œè¯„ä¼°é¢„æµ‹æ€§èƒ½
SHAP è®¡ç®—ç‰¹å¾é‡è¦æ€§	è®¡ç®—æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®
NSGA-II è¿›è¡Œç‰¹å¾ä¼˜åŒ–	é€‰æ‹©æœ€å°‘çš„ç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒé«˜å‡†ç¡®ç‡
ä¼˜åŒ–åé‡æ–°è®­ç»ƒ XGBoost	ä½¿ç”¨ç­›é€‰å‡ºçš„ç‰¹å¾é‡æ–°è®­ç»ƒæ¨¡å‹å¹¶è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡
ğŸ“Œ ä½ å¯ä»¥å¦‚ä½•ä½¿ç”¨è¿™ä¸ªä»£ç 
âœ… ç›´æ¥è¿è¡Œï¼Œå®ƒä¼šè‡ªåŠ¨ä»ç³–å°¿ç—…æ•°æ®ä¸­æ‰¾å‡ºæœ€å…³é”®çš„ç‰¹å¾
âœ… æ›¿æ¢æ•°æ®é›†ï¼Œä½ å¯ä»¥ç”¨è‡ªå·±çš„åŒ»ç–—æ•°æ®ï¼ˆå¦‚åŸºå› æ•°æ®ã€è„‘ç”µæ•°æ®ç­‰ï¼‰æ¥ç­›é€‰å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©
âœ… è°ƒæ•´ NSGA-II å‚æ•°ï¼Œå¦‚æœä½ çš„æ•°æ®æ›´å¤æ‚ï¼Œå¯ä»¥å¢åŠ  POP_SIZE æˆ– NGEN æ¥å¢å¼ºä¼˜åŒ–èƒ½åŠ›

è¿™ä¸ªæ–¹æ³•æ™ºèƒ½åœ°ç­›é€‰äº†å…³é”®ç‰¹å¾ï¼Œå‡å°‘äº†è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„é«˜å‡†ç¡®ç‡ã€‚ğŸš€ğŸ”¥
"""